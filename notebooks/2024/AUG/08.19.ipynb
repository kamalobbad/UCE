{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/oak/stanford/groups/akundaje/kobbad/UCE\")\n",
    "from model import *\n",
    "import scanpy as sc\n",
    "from tqdm.auto import tqdm\n",
    "from torch import nn, Tensor\n",
    "from evaluate import get_ESM2_embeddings\n",
    "from utils import get_ESM2_embeddings_x\n",
    "import argparse\n",
    "from accelerate import Accelerator\n",
    "from evaluate import AnndataProcessor\n",
    "from eval_data import MultiDatasetSentences, MultiDatasetSentenceCollator\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--genes_to_pe_idx'], dest='genes_to_pe_idx', nargs=None, const=None, default='./model_files/gene_to_pe_index.pkl', type=<class 'str'>, choices=None, help='Path to gene to protein embedding index mapping', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description='Embed a single anndata using UCE.')\n",
    "\n",
    "# Anndata Processing Arguments\n",
    "parser.add_argument('--adata_path', type=str,\n",
    "                    default=None,\n",
    "                    help='Full path to the anndata you want to embed.')\n",
    "parser.add_argument('--dir', type=str,\n",
    "                    default=\"./\",\n",
    "                    help='Working folder where all files will be saved.')\n",
    "parser.add_argument('--species', type=str, default=\"human\",\n",
    "                    help='Species of the anndata.')\n",
    "parser.add_argument('--filter', type=bool, default=True,\n",
    "                    help='Additional gene/cell filtering on the anndata.')\n",
    "parser.add_argument('--skip', type=bool, default=True,\n",
    "                    help='Skip datasets that appear to have already been created.')\n",
    "\n",
    "# Model Arguments\n",
    "parser.add_argument('--model_loc', type=str,\n",
    "                    default=None,\n",
    "                    help='Location of the model.')\n",
    "parser.add_argument('--batch_size', type=int, default=25,\n",
    "                    help='Batch size.')\n",
    "parser.add_argument('--pad_length', type=int, default=1536,\n",
    "                    help='Batch size.')\n",
    "parser.add_argument(\"--pad_token_idx\", type=int, default=0,\n",
    "                    help=\"PAD token index\")\n",
    "parser.add_argument(\"--chrom_token_left_idx\", type=int, default=1,\n",
    "                    help=\"Chrom token left index\")\n",
    "parser.add_argument(\"--chrom_token_right_idx\", type=int, default=2,\n",
    "                    help=\"Chrom token right index\")\n",
    "parser.add_argument(\"--cls_token_idx\", type=int, default=3,\n",
    "                    help=\"CLS token index\")\n",
    "parser.add_argument(\"--CHROM_TOKEN_OFFSET\", type=int, default=143574,\n",
    "                    help=\"Offset index, tokens after this mark are chromosome identifiers\")\n",
    "parser.add_argument('--sample_size', type=int, default=1024,\n",
    "                    help='Number of genes sampled for cell sentence')\n",
    "parser.add_argument('--CXG', type=bool, default=True,\n",
    "                    help='Use CXG model.')\n",
    "parser.add_argument('--nlayers', type=int, default=4,\n",
    "                    help='Number of transformer layers.')\n",
    "parser.add_argument('--output_dim', type=int, default=1280,\n",
    "                    help='Output dimension.')\n",
    "parser.add_argument('--d_hid', type=int, default=5120,\n",
    "                    help='Hidden dimension.')\n",
    "parser.add_argument('--token_dim', type=int, default=5120,\n",
    "                    help='Token dimension.')\n",
    "parser.add_argument('--multi_gpu', type=bool, default=False,\n",
    "                    help='Use multiple GPUs')\n",
    "\n",
    "# Misc Arguments\n",
    "parser.add_argument(\"--spec_chrom_csv_path\",\n",
    "                    default=\"./model_files/species_chrom.csv\", type=str,\n",
    "                    help=\"CSV Path for species genes to chromosomes and start locations.\")\n",
    "parser.add_argument(\"--token_file\",\n",
    "                    default=\"./model_files/all_tokens.torch\", type=str,\n",
    "                    help=\"Path for token embeddings.\")\n",
    "parser.add_argument(\"--protein_embeddings_dir\",\n",
    "                    default=\"./model_files/protein_embeddings/\", type=str,\n",
    "                    help=\"Directory where protein embedding .pt files are stored.\")\n",
    "parser.add_argument(\"--offset_pkl_path\",\n",
    "                    default=\"./model_files/species_offsets.pkl\", type=str,\n",
    "                        help=\"PKL file which contains offsets for each species.\")\n",
    "\n",
    "# masking arguments\n",
    "parser.add_argument(\"--genes_to_mask\", \n",
    "                    nargs='+',\n",
    "                    default= None,\n",
    "                    type=str,\n",
    "                    help=\"List of genes to mask\")\n",
    "\n",
    "parser.add_argument(\"--genes_to_pe_idx\",\n",
    "                    default=\"./model_files/gene_to_pe_index.pkl\",type=str,\n",
    "                    help=\"Path to gene to protein embedding index mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STAT2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.genes_to_mask = [\"STAT2\"]\n",
    "\n",
    "args.genes_to_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_loc = \"/oak/stanford/groups/akundaje/kobbad/UCE/model_files/4layer_model.torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set up the model ####\n",
    "token_dim = args.token_dim\n",
    "emsize = 1280  # embedding dimension\n",
    "d_hid = args.d_hid  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = args.nlayers  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 20  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.05  # dropout probability\n",
    "model = TransformerModel(token_dim=token_dim, d_model=emsize, nhead=nhead,\n",
    "                            d_hid=d_hid,\n",
    "                            nlayers=nlayers, dropout=dropout,\n",
    "                            output_dim=args.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize as empty\n",
    "empty_pe = torch.zeros(145469, 5120)\n",
    "empty_pe.requires_grad = False\n",
    "model.pe_embedding = nn.Embedding.from_pretrained(empty_pe)\n",
    "model.load_state_dict(torch.load(args.model_loc, map_location=\"cpu\"),\n",
    "                        strict=True)\n",
    "# Load in the real token embeddings\n",
    "all_pe = get_ESM2_embeddings(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_pe.shape[0] != 145469: \n",
    "        all_pe.requires_grad = False\n",
    "        model.pe_embedding = nn.Embedding.from_pretrained(all_pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model = model.eval()\n",
    "accelerator = Accelerator(project_dir=args.dir)\n",
    "model = accelerator.prepare(model)\n",
    "batch_size = args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sample AnnData: 10k pbmcs dataset\n"
     ]
    }
   ],
   "source": [
    "processor = AnndataProcessor(args, accelerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10k_pbmcs_proc already processed. Skipping\n"
     ]
    }
   ],
   "source": [
    "processor.preprocess_anndata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PE Idx, Chrom and Starts files already created\n"
     ]
    }
   ],
   "source": [
    "processor.generate_idxs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 11990 × 10809\n",
       "    obs: 'n_counts', 'batch', 'labels', 'str_labels', 'cell_type', 'n_genes'\n",
       "    var: 'gene_symbols', 'n_counts-0', 'n_counts-1', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'n_cells'\n",
       "    uns: 'cell_types', 'hvg'\n",
       "    obsm: 'design', 'normalized_qc', 'qc_pc', 'raw_qc'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(processor.shapes_dict_path, \"rb\") as f:\n",
    "            shapes_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiDatasetSentences(sorted_dataset_names=[processor.name],\n",
    "                                shapes_dict=shapes_dict,\n",
    "                                args=args, npzs_dir=args.dir,\n",
    "                                dataset_to_protein_embeddings_path=processor.pe_idx_path,\n",
    "                                datasets_to_chroms_path=processor.chroms_path,\n",
    "                                datasets_to_starts_path=processor.starts_path\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10809])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset_to_protein_embeddings[dataset.datasets[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10k_pbmcs_proc']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10809])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seems to have the mapping from gene to protein embeddings\n",
    "dataset.dataset_to_protein_embeddings['10k_pbmcs_proc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10809,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset_to_starts['10k_pbmcs_proc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28041, 26112, 20529,  ..., 23672, 23677, 23680])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset_to_protein_embeddings[dataset.datasets[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STAT2']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.genes_to_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_dataset_sentence_collator = MultiDatasetSentenceCollator(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29700]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_dataset_sentence_collator.idx_to_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                            collate_fn=multi_dataset_sentence_collator,\n",
    "                            num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking done\n",
      "Masking done\n"
     ]
    }
   ],
   "source": [
    "x = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  6, 928],\n",
       "        [  6, 929],\n",
       "        [  8, 801]], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(x[0] == 29700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1][8, 801]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = accelerator.prepare(dataloader)\n",
    "pbar = tqdm(dataloader, disable=not accelerator.is_local_main_process)\n",
    "dataset_embeds = []\n",
    "with torch.no_grad():\n",
    "    for batch in pbar:\n",
    "        batch_sentences, mask, idxs = batch[0], batch[1], batch[2]\n",
    "        batch_sentences = batch_sentences.permute(1, 0)\n",
    "        batch_sentences_save = batch_sentences.permute(1, 0)\n",
    "        if args.multi_gpu:\n",
    "            batch_sentences = model.module.pe_embedding(batch_sentences.long())\n",
    "        else:\n",
    "            batch_sentences = model.pe_embedding(batch_sentences.long())\n",
    "        batch_sentences = nn.functional.normalize(batch_sentences,\n",
    "                                                    dim=2)  # Normalize token outputs now\n",
    "        pred, embedding = model.forward(batch_sentences, mask=mask)\n",
    "        # Fix for duplicates in last batch\n",
    "        accelerator.wait_for_everyone()\n",
    "        embeddings = accelerator.gather_for_metrics((embedding))\n",
    "        if accelerator.is_main_process:\n",
    "            dataset_embeds.append(embeddings.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]], device='cuda:0')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(batch_sentences_save[0] == 144155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], device='cuda:0')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0,torch.nonzero(batch_sentences_save[0] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([144186, 144185, 144159, 144158, 144157, 144156, 144155, 144154,\n",
       "       144153, 144152, 144151, 144150, 144149, 144148, 144147, 144146,\n",
       "       144145, 144144, 144143, 144142, 144141, 144140, 144139, 144138,\n",
       "        33086,  33065,  32974,  32974,  32847,  32804,  32804,  32729,\n",
       "        32729,  32728,  32600,  32600,  32599,  32558,  32511,  32511,\n",
       "        32511,  32511,  32494,  32419,  32419,  32411,  32411,  32400,\n",
       "        32400,  32386,  32384,  32352,  32352,  32314,  32240,  32236,\n",
       "        32236,  32236,  32226,  32150,  32105,  32098,  32098,  32098,\n",
       "        32098,  32094,  32087,  32046,  32046,  32012,  32012,  31938,\n",
       "        31902,  31868,  31780,  31780,  31780,  31774,  31774,  31745,\n",
       "        31745,  31745,  31721,  31721,  31701,  31696,  31696,  31696,\n",
       "        31687,  31633,  31633,  31621,  31611,  31611,  31611,  31420,\n",
       "        31419,  31419,  31419,  31387], dtype=int32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cast to int\n",
    "np.sort(batch_sentences_save[0].int().cpu().numpy())[::-1][0:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 1075])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the gene idxs which are mapped above\n",
    "batch_sentences_save[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2758,  0.8424,  0.2497,  ...,  1.1378,  1.6793, -1.8231],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pe_embedding(torch.tensor(3).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0070, -0.0088,  0.0030,  ...,  0.0112, -0.0101, -0.0255]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.normalize(all_pe[144146].unsqueeze(0), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3609, -0.1782,  0.8830,  ...,  0.5165, -0.9954,  0.5466])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pe[144150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0072, -0.0125,  0.0050,  ...,  0.0057, -0.0163, -0.0150],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences[:,0,:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14948., device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences_save[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1075, 25, 5120])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 1280])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.gene_embedding_layer(batch_sentences)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 1280])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(embedding, batch_sentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.3502],\n",
       "        [-4.8144],\n",
       "        [-5.8105],\n",
       "        [-2.8324],\n",
       "        [-1.6371],\n",
       "        [-1.5982],\n",
       "        [-2.2231],\n",
       "        [-6.7526],\n",
       "        [-3.2576],\n",
       "        [-4.5858],\n",
       "        [-1.4756],\n",
       "        [-4.5196],\n",
       "        [-1.8379],\n",
       "        [-2.2768],\n",
       "        [-3.8854],\n",
       "        [-4.0805],\n",
       "        [-5.2052],\n",
       "        [-2.9048],\n",
       "        [-1.4073],\n",
       "        [-3.0574],\n",
       "        [-2.7870],\n",
       "        [-3.2805],\n",
       "        [-3.4762],\n",
       "        [-1.9117],\n",
       "        [-1.6429]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in anndata 10k_pbmcs_proc_uce_adata.h5ad\n",
    "adata = sc.read(\"10k_pbmcs_proc_uce_adata.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_symbols</th>\n",
       "      <th>n_counts-0</th>\n",
       "      <th>n_counts-1</th>\n",
       "      <th>n_counts</th>\n",
       "      <th>highly_variable</th>\n",
       "      <th>highly_variable_rank</th>\n",
       "      <th>means</th>\n",
       "      <th>variances</th>\n",
       "      <th>variances_norm</th>\n",
       "      <th>n_cells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FOXO3</th>\n",
       "      <td>FOXO3</td>\n",
       "      <td>865.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>True</td>\n",
       "      <td>6208.0</td>\n",
       "      <td>0.103503</td>\n",
       "      <td>0.109813</td>\n",
       "      <td>0.955795</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gene_symbols  n_counts-0  n_counts-1  n_counts  highly_variable  \\\n",
       "FOXO3        FOXO3       865.0       417.0    1241.0             True   \n",
       "\n",
       "       highly_variable_rank     means  variances  variances_norm  n_cells  \n",
       "FOXO3                6208.0  0.103503   0.109813        0.955795     1150  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var[adata.var[\"gene_symbols\"]==\"FOXO3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAMD11      SAMD11\n",
       "PLEKHN1    PLEKHN1\n",
       "HES4          HES4\n",
       "ISG15        ISG15\n",
       "AGRN          AGRN\n",
       "            ...   \n",
       "MT-ATP8    MT-ATP8\n",
       "MT-ATP6    MT-ATP6\n",
       "MT-CO3      MT-CO3\n",
       "MT-ND4      MT-ND4\n",
       "MT-ND6      MT-ND6\n",
       "Name: gene_symbols, Length: 10809, dtype: category\n",
       "Categories (10809, object): ['A1BG', 'A2M', 'AAAS', 'AACS', ..., 'ZYG11B', 'ZYX', 'ZZEF1', 'ZZZ3']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var[\"gene_symbols\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CD4 T cells', 'CD14+ Monocytes', 'CD8 T cells', 'B cells', 'Other', 'Dendritic Cells', 'FCGR3A+ Monocytes', 'NK cells', 'Megakaryocytes']\n",
       "Categories (9, object): ['B cells', 'CD4 T cells', 'CD8 T cells', 'CD14+ Monocytes', ..., 'FCGR3A+ Monocytes', 'Megakaryocytes', 'NK cells', 'Other']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs['cell_type'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11990, 1280)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obsm['X_uce'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 11990 × 10809\n",
       "    obs: 'n_counts', 'batch', 'labels', 'str_labels', 'cell_type', 'n_genes'\n",
       "    var: 'gene_symbols', 'n_counts-0', 'n_counts-1', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'n_cells'\n",
       "    uns: 'cell_types', 'hvg'\n",
       "    obsm: 'X_uce', 'design', 'normalized_qc', 'qc_pc', 'raw_qc'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_symbols</th>\n",
       "      <th>n_counts-0</th>\n",
       "      <th>n_counts-1</th>\n",
       "      <th>n_counts</th>\n",
       "      <th>highly_variable</th>\n",
       "      <th>highly_variable_rank</th>\n",
       "      <th>means</th>\n",
       "      <th>variances</th>\n",
       "      <th>variances_norm</th>\n",
       "      <th>n_cells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MTOR</th>\n",
       "      <td>MTOR</td>\n",
       "      <td>197.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>True</td>\n",
       "      <td>6917.0</td>\n",
       "      <td>0.024854</td>\n",
       "      <td>0.025239</td>\n",
       "      <td>0.949541</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gene_symbols  n_counts-0  n_counts-1  n_counts  highly_variable  \\\n",
       "MTOR         MTOR       197.0       108.0     298.0             True   \n",
       "\n",
       "      highly_variable_rank     means  variances  variances_norm  n_cells  \n",
       "MTOR                6917.0  0.024854   0.025239        0.949541      292  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var[adata.var['gene_symbols']=='MTOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.memmap(\"10k_pbmcs_proc_counts.npz\", dtype='int64', mode='r', shape = (11990,10809))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 2,\n",
       " 2.0: 24,\n",
       " 3.0: 1,\n",
       " 13466.0: 2,\n",
       " 13534.0: 2,\n",
       " 13554.0: 1,\n",
       " 13598.0: 1,\n",
       " 13600.0: 1,\n",
       " 13624.0: 3,\n",
       " 13671.0: 3,\n",
       " 13674.0: 3,\n",
       " 13691.0: 1,\n",
       " 13708.0: 2,\n",
       " 13798.0: 1,\n",
       " 13833.0: 3,\n",
       " 13855.0: 3,\n",
       " 13924.0: 1,\n",
       " 13933.0: 2,\n",
       " 13990.0: 1,\n",
       " 14017.0: 2,\n",
       " 14075.0: 1,\n",
       " 14149.0: 2,\n",
       " 14155.0: 1,\n",
       " 14241.0: 2,\n",
       " 14248.0: 1,\n",
       " 14249.0: 2,\n",
       " 14270.0: 2,\n",
       " 14332.0: 4,\n",
       " 14354.0: 2,\n",
       " 14364.0: 1,\n",
       " 14375.0: 1,\n",
       " 14432.0: 1,\n",
       " 14474.0: 4,\n",
       " 14537.0: 3,\n",
       " 14548.0: 2,\n",
       " 14576.0: 3,\n",
       " 14639.0: 2,\n",
       " 14773.0: 2,\n",
       " 14906.0: 1,\n",
       " 14948.0: 1,\n",
       " 14996.0: 1,\n",
       " 15023.0: 3,\n",
       " 15044.0: 1,\n",
       " 15125.0: 3,\n",
       " 15179.0: 4,\n",
       " 15252.0: 1,\n",
       " 15523.0: 1,\n",
       " 15540.0: 1,\n",
       " 15594.0: 1,\n",
       " 15660.0: 1,\n",
       " 15706.0: 2,\n",
       " 15711.0: 1,\n",
       " 15736.0: 1,\n",
       " 15755.0: 1,\n",
       " 16005.0: 1,\n",
       " 16035.0: 1,\n",
       " 16066.0: 2,\n",
       " 16068.0: 5,\n",
       " 16069.0: 1,\n",
       " 16073.0: 1,\n",
       " 16078.0: 1,\n",
       " 16086.0: 4,\n",
       " 16088.0: 1,\n",
       " 16092.0: 3,\n",
       " 16097.0: 1,\n",
       " 16144.0: 1,\n",
       " 16200.0: 1,\n",
       " 16202.0: 2,\n",
       " 16222.0: 1,\n",
       " 16227.0: 1,\n",
       " 16271.0: 1,\n",
       " 16335.0: 2,\n",
       " 16429.0: 3,\n",
       " 16477.0: 1,\n",
       " 16496.0: 3,\n",
       " 16594.0: 2,\n",
       " 16757.0: 1,\n",
       " 16785.0: 1,\n",
       " 16902.0: 1,\n",
       " 16922.0: 2,\n",
       " 16925.0: 1,\n",
       " 16942.0: 1,\n",
       " 16947.0: 4,\n",
       " 17010.0: 1,\n",
       " 17012.0: 2,\n",
       " 17027.0: 1,\n",
       " 17057.0: 1,\n",
       " 17066.0: 1,\n",
       " 17080.0: 4,\n",
       " 17081.0: 2,\n",
       " 17094.0: 2,\n",
       " 17186.0: 1,\n",
       " 17268.0: 2,\n",
       " 17275.0: 2,\n",
       " 17279.0: 1,\n",
       " 17336.0: 1,\n",
       " 17442.0: 4,\n",
       " 17489.0: 2,\n",
       " 17513.0: 1,\n",
       " 17514.0: 2,\n",
       " 17592.0: 6,\n",
       " 17675.0: 1,\n",
       " 17708.0: 1,\n",
       " 17713.0: 1,\n",
       " 17813.0: 1,\n",
       " 17890.0: 2,\n",
       " 17910.0: 1,\n",
       " 17989.0: 1,\n",
       " 17996.0: 2,\n",
       " 18009.0: 3,\n",
       " 18069.0: 2,\n",
       " 18093.0: 3,\n",
       " 18117.0: 4,\n",
       " 18131.0: 2,\n",
       " 18132.0: 1,\n",
       " 18224.0: 15,\n",
       " 18246.0: 1,\n",
       " 18271.0: 1,\n",
       " 18293.0: 2,\n",
       " 18309.0: 4,\n",
       " 18316.0: 1,\n",
       " 18339.0: 6,\n",
       " 18356.0: 1,\n",
       " 18377.0: 1,\n",
       " 18454.0: 2,\n",
       " 18455.0: 2,\n",
       " 18459.0: 2,\n",
       " 18554.0: 2,\n",
       " 18586.0: 2,\n",
       " 18670.0: 2,\n",
       " 18772.0: 1,\n",
       " 18782.0: 1,\n",
       " 18876.0: 5,\n",
       " 18986.0: 3,\n",
       " 18990.0: 3,\n",
       " 19018.0: 1,\n",
       " 19080.0: 2,\n",
       " 19131.0: 1,\n",
       " 19219.0: 1,\n",
       " 19222.0: 3,\n",
       " 19253.0: 1,\n",
       " 19299.0: 4,\n",
       " 19300.0: 1,\n",
       " 19413.0: 1,\n",
       " 19415.0: 3,\n",
       " 19437.0: 1,\n",
       " 19442.0: 1,\n",
       " 19570.0: 3,\n",
       " 19799.0: 2,\n",
       " 19821.0: 2,\n",
       " 19825.0: 2,\n",
       " 19854.0: 1,\n",
       " 19862.0: 1,\n",
       " 19873.0: 1,\n",
       " 19895.0: 1,\n",
       " 19969.0: 1,\n",
       " 20048.0: 1,\n",
       " 20215.0: 1,\n",
       " 20231.0: 1,\n",
       " 20251.0: 1,\n",
       " 20275.0: 1,\n",
       " 20400.0: 1,\n",
       " 20401.0: 2,\n",
       " 20477.0: 1,\n",
       " 20478.0: 2,\n",
       " 20495.0: 1,\n",
       " 20496.0: 2,\n",
       " 20597.0: 2,\n",
       " 20605.0: 1,\n",
       " 20626.0: 1,\n",
       " 20629.0: 2,\n",
       " 20640.0: 1,\n",
       " 20660.0: 2,\n",
       " 20691.0: 1,\n",
       " 20819.0: 2,\n",
       " 20824.0: 1,\n",
       " 20835.0: 2,\n",
       " 20879.0: 1,\n",
       " 20891.0: 4,\n",
       " 20903.0: 3,\n",
       " 20929.0: 3,\n",
       " 20942.0: 1,\n",
       " 20951.0: 2,\n",
       " 20953.0: 6,\n",
       " 20974.0: 1,\n",
       " 21258.0: 1,\n",
       " 21302.0: 2,\n",
       " 21315.0: 1,\n",
       " 21333.0: 2,\n",
       " 21346.0: 3,\n",
       " 21352.0: 1,\n",
       " 21382.0: 1,\n",
       " 21421.0: 1,\n",
       " 21436.0: 4,\n",
       " 21448.0: 1,\n",
       " 21474.0: 2,\n",
       " 21476.0: 3,\n",
       " 21479.0: 2,\n",
       " 21485.0: 2,\n",
       " 21503.0: 2,\n",
       " 21504.0: 2,\n",
       " 21514.0: 1,\n",
       " 21536.0: 1,\n",
       " 21543.0: 1,\n",
       " 21558.0: 3,\n",
       " 21627.0: 1,\n",
       " 21630.0: 6,\n",
       " 21631.0: 6,\n",
       " 21673.0: 2,\n",
       " 21814.0: 1,\n",
       " 21818.0: 2,\n",
       " 21860.0: 2,\n",
       " 21954.0: 3,\n",
       " 21955.0: 3,\n",
       " 22032.0: 1,\n",
       " 22071.0: 2,\n",
       " 22326.0: 1,\n",
       " 22350.0: 3,\n",
       " 22353.0: 2,\n",
       " 22365.0: 2,\n",
       " 22388.0: 2,\n",
       " 22394.0: 1,\n",
       " 22466.0: 2,\n",
       " 22503.0: 2,\n",
       " 22514.0: 3,\n",
       " 22535.0: 3,\n",
       " 22570.0: 1,\n",
       " 22573.0: 2,\n",
       " 22677.0: 2,\n",
       " 22715.0: 2,\n",
       " 22721.0: 8,\n",
       " 22747.0: 1,\n",
       " 22763.0: 2,\n",
       " 22866.0: 2,\n",
       " 22977.0: 1,\n",
       " 22979.0: 1,\n",
       " 23020.0: 1,\n",
       " 23031.0: 1,\n",
       " 23057.0: 2,\n",
       " 23248.0: 3,\n",
       " 23271.0: 4,\n",
       " 23308.0: 1,\n",
       " 23340.0: 1,\n",
       " 23364.0: 1,\n",
       " 23425.0: 3,\n",
       " 23534.0: 1,\n",
       " 23539.0: 1,\n",
       " 23549.0: 1,\n",
       " 23570.0: 1,\n",
       " 23580.0: 1,\n",
       " 23582.0: 3,\n",
       " 23606.0: 2,\n",
       " 23611.0: 4,\n",
       " 23653.0: 1,\n",
       " 23657.0: 1,\n",
       " 23670.0: 3,\n",
       " 23671.0: 2,\n",
       " 23672.0: 4,\n",
       " 23674.0: 2,\n",
       " 23677.0: 1,\n",
       " 23690.0: 2,\n",
       " 23726.0: 1,\n",
       " 23830.0: 2,\n",
       " 23925.0: 3,\n",
       " 23932.0: 3,\n",
       " 23938.0: 2,\n",
       " 23940.0: 1,\n",
       " 23949.0: 3,\n",
       " 23950.0: 1,\n",
       " 23952.0: 1,\n",
       " 23956.0: 1,\n",
       " 23980.0: 1,\n",
       " 23989.0: 1,\n",
       " 24052.0: 2,\n",
       " 24079.0: 2,\n",
       " 24104.0: 2,\n",
       " 24232.0: 2,\n",
       " 24235.0: 1,\n",
       " 24253.0: 2,\n",
       " 24379.0: 4,\n",
       " 24398.0: 2,\n",
       " 24421.0: 1,\n",
       " 24450.0: 2,\n",
       " 24529.0: 1,\n",
       " 24541.0: 1,\n",
       " 24610.0: 1,\n",
       " 24639.0: 4,\n",
       " 24724.0: 1,\n",
       " 24736.0: 3,\n",
       " 25288.0: 3,\n",
       " 25343.0: 2,\n",
       " 25442.0: 1,\n",
       " 25581.0: 3,\n",
       " 25644.0: 4,\n",
       " 25670.0: 1,\n",
       " 25698.0: 1,\n",
       " 25777.0: 7,\n",
       " 25798.0: 1,\n",
       " 25801.0: 1,\n",
       " 25804.0: 1,\n",
       " 25828.0: 4,\n",
       " 25831.0: 2,\n",
       " 25838.0: 1,\n",
       " 25856.0: 2,\n",
       " 25874.0: 2,\n",
       " 25878.0: 2,\n",
       " 25919.0: 1,\n",
       " 25927.0: 1,\n",
       " 25948.0: 2,\n",
       " 26113.0: 2,\n",
       " 26137.0: 1,\n",
       " 26191.0: 3,\n",
       " 26195.0: 1,\n",
       " 26252.0: 4,\n",
       " 26356.0: 1,\n",
       " 26359.0: 1,\n",
       " 26372.0: 2,\n",
       " 26379.0: 1,\n",
       " 26387.0: 3,\n",
       " 26407.0: 1,\n",
       " 26416.0: 2,\n",
       " 26480.0: 1,\n",
       " 26499.0: 2,\n",
       " 26562.0: 2,\n",
       " 26569.0: 1,\n",
       " 26581.0: 1,\n",
       " 26600.0: 1,\n",
       " 26657.0: 1,\n",
       " 26776.0: 1,\n",
       " 26801.0: 3,\n",
       " 26802.0: 1,\n",
       " 26811.0: 3,\n",
       " 26853.0: 1,\n",
       " 26865.0: 1,\n",
       " 26866.0: 2,\n",
       " 26902.0: 1,\n",
       " 26907.0: 2,\n",
       " 26921.0: 1,\n",
       " 27002.0: 1,\n",
       " 27008.0: 1,\n",
       " 27009.0: 3,\n",
       " 27030.0: 2,\n",
       " 27036.0: 1,\n",
       " 27088.0: 4,\n",
       " 27101.0: 1,\n",
       " 27105.0: 1,\n",
       " 27129.0: 1,\n",
       " 27149.0: 2,\n",
       " 27155.0: 2,\n",
       " 27157.0: 2,\n",
       " 27158.0: 2,\n",
       " 27159.0: 1,\n",
       " 27171.0: 4,\n",
       " 27180.0: 1,\n",
       " 27201.0: 1,\n",
       " 27292.0: 1,\n",
       " 27309.0: 1,\n",
       " 27330.0: 1,\n",
       " 27334.0: 1,\n",
       " 27341.0: 1,\n",
       " 27355.0: 3,\n",
       " 27406.0: 2,\n",
       " 27417.0: 1,\n",
       " 27440.0: 2,\n",
       " 27444.0: 2,\n",
       " 27450.0: 3,\n",
       " 27481.0: 3,\n",
       " 27509.0: 1,\n",
       " 27641.0: 2,\n",
       " 27653.0: 2,\n",
       " 27689.0: 1,\n",
       " 27703.0: 1,\n",
       " 27725.0: 2,\n",
       " 27752.0: 5,\n",
       " 27778.0: 8,\n",
       " 27804.0: 7,\n",
       " 27805.0: 6,\n",
       " 27808.0: 2,\n",
       " 27812.0: 4,\n",
       " 27824.0: 5,\n",
       " 27831.0: 9,\n",
       " 27834.0: 10,\n",
       " 27837.0: 6,\n",
       " 27838.0: 5,\n",
       " 27853.0: 5,\n",
       " 27854.0: 3,\n",
       " 27856.0: 1,\n",
       " 27867.0: 5,\n",
       " 27873.0: 1,\n",
       " 27878.0: 2,\n",
       " 27897.0: 1,\n",
       " 27927.0: 1,\n",
       " 27946.0: 1,\n",
       " 28004.0: 8,\n",
       " 28006.0: 3,\n",
       " 28011.0: 2,\n",
       " 28028.0: 1,\n",
       " 28066.0: 2,\n",
       " 28076.0: 1,\n",
       " 28081.0: 4,\n",
       " 28305.0: 1,\n",
       " 28472.0: 1,\n",
       " 28482.0: 2,\n",
       " 28570.0: 1,\n",
       " 28575.0: 3,\n",
       " 28580.0: 3,\n",
       " 28612.0: 1,\n",
       " 28732.0: 1,\n",
       " 28752.0: 4,\n",
       " 28777.0: 5,\n",
       " 28808.0: 2,\n",
       " 28898.0: 1,\n",
       " 28906.0: 1,\n",
       " 29054.0: 1,\n",
       " 29064.0: 1,\n",
       " 29069.0: 2,\n",
       " 29091.0: 1,\n",
       " 29198.0: 1,\n",
       " 29201.0: 2,\n",
       " 29203.0: 2,\n",
       " 29262.0: 1,\n",
       " 29268.0: 2,\n",
       " 29444.0: 3,\n",
       " 29470.0: 1,\n",
       " 29475.0: 1,\n",
       " 29570.0: 1,\n",
       " 29571.0: 2,\n",
       " 29598.0: 5,\n",
       " 29621.0: 2,\n",
       " 29665.0: 1,\n",
       " 29750.0: 3,\n",
       " 29775.0: 2,\n",
       " 29777.0: 1,\n",
       " 29844.0: 2,\n",
       " 29880.0: 1,\n",
       " 29913.0: 1,\n",
       " 29914.0: 1,\n",
       " 30031.0: 3,\n",
       " 30040.0: 2,\n",
       " 30046.0: 2,\n",
       " 30103.0: 1,\n",
       " 30111.0: 1,\n",
       " 30209.0: 2,\n",
       " 30346.0: 3,\n",
       " 30357.0: 2,\n",
       " 30358.0: 1,\n",
       " 30366.0: 1,\n",
       " 30398.0: 2,\n",
       " 30481.0: 1,\n",
       " 30491.0: 1,\n",
       " 30500.0: 1,\n",
       " 30501.0: 1,\n",
       " 30510.0: 2,\n",
       " 30528.0: 2,\n",
       " 30590.0: 4,\n",
       " 30618.0: 1,\n",
       " 30719.0: 2,\n",
       " 30754.0: 2,\n",
       " 30775.0: 2,\n",
       " 30784.0: 1,\n",
       " 30815.0: 3,\n",
       " 30867.0: 4,\n",
       " 30870.0: 5,\n",
       " 30909.0: 1,\n",
       " 30925.0: 3,\n",
       " 30949.0: 2,\n",
       " 30981.0: 2,\n",
       " 30995.0: 1,\n",
       " 31041.0: 1,\n",
       " 31068.0: 5,\n",
       " 31069.0: 1,\n",
       " 31070.0: 2,\n",
       " 31143.0: 2,\n",
       " 31209.0: 3,\n",
       " 31387.0: 1,\n",
       " 31419.0: 3,\n",
       " 31420.0: 1,\n",
       " 31611.0: 3,\n",
       " 31621.0: 1,\n",
       " 31633.0: 2,\n",
       " 31687.0: 1,\n",
       " 31696.0: 3,\n",
       " 31701.0: 1,\n",
       " 31721.0: 2,\n",
       " 31745.0: 3,\n",
       " 31774.0: 2,\n",
       " 31780.0: 3,\n",
       " 31868.0: 1,\n",
       " 31902.0: 1,\n",
       " 31938.0: 1,\n",
       " 32012.0: 2,\n",
       " 32046.0: 2,\n",
       " 32087.0: 1,\n",
       " 32094.0: 1,\n",
       " 32098.0: 4,\n",
       " 32105.0: 1,\n",
       " 32150.0: 1,\n",
       " 32226.0: 1,\n",
       " 32236.0: 3,\n",
       " 32240.0: 1,\n",
       " 32314.0: 1,\n",
       " 32352.0: 2,\n",
       " 32384.0: 1,\n",
       " 32386.0: 1,\n",
       " 32400.0: 2,\n",
       " 32411.0: 2,\n",
       " 32419.0: 2,\n",
       " 32494.0: 1,\n",
       " 32511.0: 4,\n",
       " 32558.0: 1,\n",
       " 32599.0: 1,\n",
       " 32600.0: 2,\n",
       " 32728.0: 1,\n",
       " 32729.0: 2,\n",
       " 32804.0: 2,\n",
       " 32847.0: 1,\n",
       " 32974.0: 2,\n",
       " 33065.0: 1,\n",
       " 33086.0: 1,\n",
       " 144138.0: 1,\n",
       " 144139.0: 1,\n",
       " 144140.0: 1,\n",
       " 144141.0: 1,\n",
       " 144142.0: 1,\n",
       " 144143.0: 1,\n",
       " 144144.0: 1,\n",
       " 144145.0: 1,\n",
       " 144146.0: 1,\n",
       " 144147.0: 1,\n",
       " 144148.0: 1,\n",
       " 144149.0: 1,\n",
       " 144150.0: 1,\n",
       " 144151.0: 1,\n",
       " 144152.0: 1,\n",
       " 144153.0: 1,\n",
       " 144154.0: 1,\n",
       " 144155.0: 1,\n",
       " 144156.0: 1,\n",
       " 144157.0: 1,\n",
       " 144158.0: 1,\n",
       " 144159.0: 1,\n",
       " 144185.0: 1,\n",
       " 144186.0: 1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens, counts = np.unique(batch_sentences_save[0].cpu().numpy(), return_counts=True)\n",
    "\n",
    "counts = dict(zip(tokens, counts))\n",
    "\n",
    "# sort by counts\n",
    "sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 1), dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(batch_sentences_save[0].cpu().numpy() == 13491.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0246,  0.0061,  0.0222,  ..., -0.0028, -0.0150, -0.0100]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.normalize(all_pe[13491].unsqueeze(0), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0341,  0.0098,  0.0111,  ..., -0.0083, -0.0130, -0.0190]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.normalize(batch_sentences[871,0,:].unsqueeze(0), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(batch_sentences[0].cpu().numpy() == 13491)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0224, -0.0055, -0.0064,  ..., -0.0043, -0.0310,  0.0039],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences[1072,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1073., device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0000e+00, 1.4418e+05, 2.3674e+04,  ..., 2.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences_save[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.npzs_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = np.memmap(dataset.npzs_dir + f\"{dataset.datasets[0]}_counts.npz\", dtype='int64', mode='r', shape=dataset.shapes_dict[dataset.datasets[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = cts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = torch.tensor(counts).unsqueeze(0)\n",
    "weights = torch.log1p(counts)\n",
    "weights = (weights / torch.sum(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_obj = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_weights = weights\n",
    "dataset_to_protein_embeddings = dataset.dataset_to_protein_embeddings\n",
    "dataset_to_chroms = dataset.dataset_to_chroms\n",
    "dataset_to_starts = dataset.dataset_to_starts\n",
    "dataset = dataset.datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_idxs = dataset_to_protein_embeddings[dataset] # get the dataset specific protein embedding idxs\n",
    "cell_sentences = torch.zeros((counts.shape[0], args.pad_length)) # init the cell representation as 0s\n",
    "mask = torch.zeros((counts.shape[0], args.pad_length)) # start of masking the whole sequence\n",
    "chroms = dataset_to_chroms[dataset] # get the dataset specific chroms for each gene\n",
    "starts = dataset_to_starts[dataset] # get the dataset specific genomic start locations for each gene\n",
    "\n",
    "longest_seq_len = 0 # we need to keep track of this so we can subset the batch at the end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, cell in enumerate(counts):\n",
    "    weights = batch_weights[c].numpy()\n",
    "    weights = weights / sum(weights)  # RE NORM after mask\n",
    "    \n",
    "    # randomly choose the genes that will make up the sample, weighted by expression, with replacement\n",
    "    choice_idx = np.random.choice(np.arange(len(weights)),\n",
    "                                    size=args.sample_size, p=weights,\n",
    "                                    replace=True)\n",
    "    choosen_chrom = chroms[choice_idx] # get the sampled genes chromosomes\n",
    "    # order the genes by chromosome\n",
    "    chrom_sort = np.argsort(choosen_chrom)  \n",
    "    choice_idx = choice_idx[chrom_sort]\n",
    "\n",
    "    # sort the genes by start\n",
    "    new_chrom = chroms[choice_idx]\n",
    "    choosen_starts = starts[choice_idx]\n",
    "\n",
    "    ordered_choice_idx = np.full((args.pad_length),\n",
    "                                    args.cls_token_idx)  # start with cls\n",
    "    # i= 0 first token is CLS\n",
    "    i = 1  # continue on to the rest of the sequence with left bracket being assumed.\n",
    "    # Shuffle the chroms now, there's no natural order to chromosomes\n",
    "    uq_chroms = np.unique(new_chrom)\n",
    "    np.random.shuffle(uq_chroms) # shuffle\n",
    "    \n",
    "    # This loop is actually just over one cell\n",
    "    for chrom in uq_chroms:\n",
    "        # Open Chrom token\n",
    "        ordered_choice_idx[i] = int(chrom) + args.CHROM_TOKEN_OFFSET # token of this chromosome # i = 1 next token is a chrom open\n",
    "        i += 1\n",
    "        # now sort the genes by start order within the chroms\n",
    "        loc = np.where(new_chrom == chrom)[0]\n",
    "        sort_by_start = np.argsort(\n",
    "            choosen_starts[loc])  # start locations for this chromsome\n",
    "\n",
    "        to_add = choice_idx[loc[sort_by_start]]\n",
    "        ordered_choice_idx[i:(i + len(to_add))] = dataset_idxs[to_add]\n",
    "        i += len(to_add)\n",
    "        ordered_choice_idx[i] = args.chrom_token_right_idx # add the chrom sep again\n",
    "        i += 1  # add the closing token again\n",
    "\n",
    "    longest_seq_len = max(longest_seq_len, i)\n",
    "    remainder_len = (args.pad_length - i)\n",
    "\n",
    "    cell_mask = torch.concat((torch.ones(i),\n",
    "                                # pay attention to all of these tokens, ignore the rest!\n",
    "                                torch.zeros(remainder_len)))\n",
    "\n",
    "    mask[c, :] = cell_mask\n",
    "\n",
    "    ordered_choice_idx[i:] = args.pad_token_idx # the remainder of the sequence\n",
    "    cell_sentences[c, :] = torch.from_numpy(ordered_choice_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_sentences_pe = cell_sentences.long() # token indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     3, 144144,  16509,  ...,      0,      0,      0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_sentences_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33255"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_obj.dataset_to_protein_embeddings[dataset].numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SAMD11',\n",
       " 'PLEKHN1',\n",
       " 'HES4',\n",
       " 'ISG15',\n",
       " 'AGRN',\n",
       " 'C1orf159',\n",
       " 'TTLL10',\n",
       " 'TNFRSF18',\n",
       " 'TNFRSF4',\n",
       " 'SDF4',\n",
       " 'B3GALT6',\n",
       " 'SCNN1D',\n",
       " 'ACAP3',\n",
       " 'PUSL1',\n",
       " 'CPTP',\n",
       " 'TAS1R3',\n",
       " 'MXRA8',\n",
       " 'ANKRD65',\n",
       " 'ATAD3C',\n",
       " 'ATAD3B',\n",
       " 'ATAD3A',\n",
       " 'MIB2',\n",
       " 'MMP23B',\n",
       " 'CDK11B',\n",
       " 'SLC35E2B',\n",
       " 'CDK11A',\n",
       " 'NADK',\n",
       " 'GNB1',\n",
       " 'TMEM52',\n",
       " 'PRKCZ',\n",
       " 'SKI',\n",
       " 'PEX10',\n",
       " 'PLCH2',\n",
       " 'PANK4',\n",
       " 'MMEL1',\n",
       " 'MEGF6',\n",
       " 'TPRG1L',\n",
       " 'WRAP73',\n",
       " 'SMIM1',\n",
       " 'LRRC47',\n",
       " 'CEP104',\n",
       " 'DFFB',\n",
       " 'C1orf174',\n",
       " 'AJAP1',\n",
       " 'NPHP4',\n",
       " 'KCNAB2',\n",
       " 'RNF207',\n",
       " 'ICMT',\n",
       " 'GPR153',\n",
       " 'ACOT7',\n",
       " 'HES2',\n",
       " 'ESPN',\n",
       " 'TNFRSF25',\n",
       " 'PLEKHG5',\n",
       " 'NOL9',\n",
       " 'ZBTB48',\n",
       " 'KLHL21',\n",
       " 'PHF13',\n",
       " 'THAP3',\n",
       " 'DNAJC11',\n",
       " 'VAMP3',\n",
       " 'PER3',\n",
       " 'UTS2',\n",
       " 'TNFRSF9',\n",
       " 'PARK7',\n",
       " 'SLC45A1',\n",
       " 'RERE',\n",
       " 'ENO1',\n",
       " 'CA6',\n",
       " 'SLC2A5',\n",
       " 'GPR157',\n",
       " 'H6PD',\n",
       " 'SPSB1',\n",
       " 'SLC25A33',\n",
       " 'PIK3CD',\n",
       " 'CLSTN1',\n",
       " 'CTNNBIP1',\n",
       " 'LZIC',\n",
       " 'NMNAT1',\n",
       " 'RBP7',\n",
       " 'UBE4B',\n",
       " 'KIF1B',\n",
       " 'PGD',\n",
       " 'DFFA',\n",
       " 'PEX14',\n",
       " 'CASZ1',\n",
       " 'C1orf127',\n",
       " 'TARDBP',\n",
       " 'SRM',\n",
       " 'EXOSC10',\n",
       " 'MTOR',\n",
       " 'UBIAD1',\n",
       " 'FBXO2',\n",
       " 'FBXO44',\n",
       " 'FBXO6',\n",
       " 'MAD2L2',\n",
       " 'DRAXIN',\n",
       " 'AGTRAP',\n",
       " 'MTHFR',\n",
       " 'CLCN6',\n",
       " 'KIAA2013',\n",
       " 'PLOD1',\n",
       " 'MFN2',\n",
       " 'MIIP',\n",
       " 'TNFRSF8',\n",
       " 'TNFRSF1B',\n",
       " 'VPS13D',\n",
       " 'DHRS3',\n",
       " 'HNRNPCL1',\n",
       " 'HNRNPCL2',\n",
       " 'PRDM2',\n",
       " 'TMEM51',\n",
       " 'FHAD1',\n",
       " 'EFHD2',\n",
       " 'CTRC',\n",
       " 'CASP9',\n",
       " 'DNAJC16',\n",
       " 'AGMAT',\n",
       " 'DDI2',\n",
       " 'PLEKHM2',\n",
       " 'FBLIM1',\n",
       " 'UQCRHL',\n",
       " 'SPEN',\n",
       " 'ZBTB17',\n",
       " 'EPHA2',\n",
       " 'ARHGEF19',\n",
       " 'FBXO42',\n",
       " 'SPATA21',\n",
       " 'CROCC',\n",
       " 'ATP13A2',\n",
       " 'SDHB',\n",
       " 'PADI2',\n",
       " 'PADI4',\n",
       " 'PADI6',\n",
       " 'RCC2',\n",
       " 'ARHGEF10L',\n",
       " 'ALDH4A1',\n",
       " 'IFFO2',\n",
       " 'UBR4',\n",
       " 'EMC1',\n",
       " 'MRTO4',\n",
       " 'AKR7A2',\n",
       " 'NBL1',\n",
       " 'TMCO4',\n",
       " 'OTUD3',\n",
       " 'PLA2G2D',\n",
       " 'PLA2G2C',\n",
       " 'UBXN10',\n",
       " 'CAMK2N1',\n",
       " 'MUL1',\n",
       " 'CDA',\n",
       " 'PINK1',\n",
       " 'DDOST',\n",
       " 'EIF4G3',\n",
       " 'ECE1',\n",
       " 'USP48',\n",
       " 'LDLRAD2',\n",
       " 'HSPG2',\n",
       " 'ZBTB40',\n",
       " 'C1QA',\n",
       " 'C1QB',\n",
       " 'EPHB2',\n",
       " 'KDM1A',\n",
       " 'LUZP1',\n",
       " 'ZNF436',\n",
       " 'TCEA3',\n",
       " 'E2F2',\n",
       " 'ID3',\n",
       " 'GALE',\n",
       " 'HMGCL',\n",
       " 'FUCA1',\n",
       " 'CNR2',\n",
       " 'IFNLR1',\n",
       " 'STPG1',\n",
       " 'NIPAL3',\n",
       " 'RCAN3',\n",
       " 'CLIC4',\n",
       " 'RUNX3',\n",
       " 'RHD',\n",
       " 'RHCE',\n",
       " 'LDLRAP1',\n",
       " 'MAN1C1',\n",
       " 'MTFR1L',\n",
       " 'PAQR7',\n",
       " 'STMN1',\n",
       " 'PAFAH2',\n",
       " 'SLC30A2',\n",
       " 'PDIK1L',\n",
       " 'ZNF593',\n",
       " 'CNKSR1',\n",
       " 'CEP85',\n",
       " 'SH3BGRL3',\n",
       " 'UBXN11',\n",
       " 'ZNF683',\n",
       " 'DHDDS',\n",
       " 'HMGN2',\n",
       " 'RPS6KA1',\n",
       " 'ARID1A',\n",
       " 'PIGV',\n",
       " 'ZDHHC18',\n",
       " 'GPN2',\n",
       " 'GPATCH3',\n",
       " 'TRNP1',\n",
       " 'SLC9A1',\n",
       " 'WDTC1',\n",
       " 'TMEM222',\n",
       " 'MAP3K6',\n",
       " 'AHDC1',\n",
       " 'FGR',\n",
       " 'IFI6',\n",
       " 'FAM76A',\n",
       " 'STX12',\n",
       " 'PPP1R8',\n",
       " 'THEMIS2',\n",
       " 'XKR8',\n",
       " 'EYA3',\n",
       " 'PTAFR',\n",
       " 'SESN2',\n",
       " 'MED18',\n",
       " 'PHACTR4',\n",
       " 'RCC1',\n",
       " 'TRNAU1AP',\n",
       " 'TAF12',\n",
       " 'GMEB1',\n",
       " 'EPB41',\n",
       " 'MECR',\n",
       " 'SDC3',\n",
       " 'PUM1',\n",
       " 'ZCCHC17',\n",
       " 'SERINC2',\n",
       " 'PEF1',\n",
       " 'COL16A1',\n",
       " 'PTP4A2',\n",
       " 'TMEM39B',\n",
       " 'KPNA6',\n",
       " 'TXLNA',\n",
       " 'CCDC28B',\n",
       " 'TMEM234',\n",
       " 'FAM167B',\n",
       " 'LCK',\n",
       " 'MARCKSL1',\n",
       " 'FAM229A',\n",
       " 'ZBTB8B',\n",
       " 'ZBTB8A',\n",
       " 'ZBTB8OS',\n",
       " 'SYNC',\n",
       " 'KIAA1522',\n",
       " 'S100PBP',\n",
       " 'RNF19B',\n",
       " 'AK2',\n",
       " 'AZIN2',\n",
       " 'ZNF362',\n",
       " 'PHC2',\n",
       " 'ZSCAN20',\n",
       " 'SMIM12',\n",
       " 'ZMYM6',\n",
       " 'ZMYM1',\n",
       " 'ZMYM4',\n",
       " 'KIAA0319L',\n",
       " 'NCDN',\n",
       " 'TFAP2E',\n",
       " 'PSMB2',\n",
       " 'C1orf216',\n",
       " 'CLSPN',\n",
       " 'AGO4',\n",
       " 'AGO1',\n",
       " 'AGO3',\n",
       " 'COL8A2',\n",
       " 'SH3D21',\n",
       " 'EVA1B',\n",
       " 'STK40',\n",
       " 'OSCP1',\n",
       " 'MRPS15',\n",
       " 'CSF3R',\n",
       " 'ZC3H12A',\n",
       " 'SNIP1',\n",
       " 'GNL2',\n",
       " 'C1orf109',\n",
       " 'CDCA8',\n",
       " 'MANEAL',\n",
       " 'YRDC',\n",
       " 'C1orf122',\n",
       " 'MTF1',\n",
       " 'INPP5B',\n",
       " 'FHL3',\n",
       " 'POU3F1',\n",
       " 'RRAGC',\n",
       " 'MYCBP',\n",
       " 'RHBDL2',\n",
       " 'MACF1',\n",
       " 'PABPC4',\n",
       " 'HPCAL4',\n",
       " 'BMP8B',\n",
       " 'TRIT1',\n",
       " 'MYCL',\n",
       " 'MFSD2A',\n",
       " 'CAP1',\n",
       " 'PPT1',\n",
       " 'RLF',\n",
       " 'ZMPSTE24',\n",
       " 'COL9A2',\n",
       " 'SMAP2',\n",
       " 'ZFP69B',\n",
       " 'ZFP69',\n",
       " 'EXO5',\n",
       " 'ZNF684',\n",
       " 'RIMS3',\n",
       " 'NFYC',\n",
       " 'CITED4',\n",
       " 'CTPS1',\n",
       " 'SCMH1',\n",
       " 'HIVEP3',\n",
       " 'FOXJ3',\n",
       " 'ZMYND12',\n",
       " 'CCDC30',\n",
       " 'YBX1',\n",
       " 'P3H1',\n",
       " 'C1orf50',\n",
       " 'SVBP',\n",
       " 'ERMAP',\n",
       " 'ZNF691',\n",
       " 'SLC2A1',\n",
       " 'EBNA1BP2',\n",
       " 'CFAP57',\n",
       " 'TIE1',\n",
       " 'CDC20',\n",
       " 'ELOVL1',\n",
       " 'MED8',\n",
       " 'SZT2',\n",
       " 'HYI',\n",
       " 'KDM4A',\n",
       " 'ST3GAL3',\n",
       " 'IPO13',\n",
       " 'DPH2',\n",
       " 'ATP6V0B',\n",
       " 'B4GALT2',\n",
       " 'CCDC24',\n",
       " 'DMAP1',\n",
       " 'ERI3',\n",
       " 'RNF220',\n",
       " 'TMEM53',\n",
       " 'KIF2C',\n",
       " 'PLK3',\n",
       " 'PTCH2',\n",
       " 'EIF2B3',\n",
       " 'HECTD3',\n",
       " 'UROD',\n",
       " 'HPDL',\n",
       " 'MUTYH',\n",
       " 'TOE1',\n",
       " 'TESK2',\n",
       " 'PRDX1',\n",
       " 'AKR1A1',\n",
       " 'NASP',\n",
       " 'CCDC17',\n",
       " 'TMEM69',\n",
       " 'IPP',\n",
       " 'PIK3R3',\n",
       " 'POMGNT1',\n",
       " 'LRRC41',\n",
       " 'NSUN4',\n",
       " 'FAAH',\n",
       " 'MKNK1',\n",
       " 'MOB3C',\n",
       " 'ATPAF1',\n",
       " 'EFCAB14',\n",
       " 'TAL1',\n",
       " 'STIL',\n",
       " 'FOXD2',\n",
       " 'SPATA6',\n",
       " 'BEND5',\n",
       " 'FAF1',\n",
       " 'CDKN2C',\n",
       " 'RNF11',\n",
       " 'TTC39A',\n",
       " 'EPS15',\n",
       " 'OSBPL9',\n",
       " 'NRDC',\n",
       " 'RAB3B',\n",
       " 'KTI12',\n",
       " 'ZFYVE9',\n",
       " 'CC2D1B',\n",
       " 'ORC1',\n",
       " 'PRPF38A',\n",
       " 'GPX7',\n",
       " 'COA7',\n",
       " 'ZYG11B',\n",
       " 'ECHDC2',\n",
       " 'CPT2',\n",
       " 'LRP8',\n",
       " 'NDC1',\n",
       " 'YIPF1',\n",
       " 'HSPB11',\n",
       " 'LRRC42',\n",
       " 'TCEANC2',\n",
       " 'MRPL37',\n",
       " 'SSBP3',\n",
       " 'ACOT11',\n",
       " 'TTC22',\n",
       " 'DHCR24',\n",
       " 'USP24',\n",
       " 'PLPP3',\n",
       " 'DAB1',\n",
       " 'OMA1',\n",
       " 'TACSTD2',\n",
       " 'MYSM1',\n",
       " 'JUN',\n",
       " 'FGGY',\n",
       " 'HOOK1',\n",
       " 'CYP2J2',\n",
       " 'NFIA',\n",
       " 'TM2D1',\n",
       " 'L1TD1',\n",
       " 'USP1',\n",
       " 'DOCK7',\n",
       " 'ATG4C',\n",
       " 'ALG6',\n",
       " 'ITGB3BP',\n",
       " 'EFCAB7',\n",
       " 'PGM1',\n",
       " 'ROR1',\n",
       " 'CACHD1',\n",
       " 'RAVER2',\n",
       " 'AK4',\n",
       " 'DNAJC6',\n",
       " 'LEPROT',\n",
       " 'LEPR',\n",
       " 'PDE4B',\n",
       " 'MIER1',\n",
       " 'SLC35D1',\n",
       " 'IL23R',\n",
       " 'IL12RB2',\n",
       " 'GADD45A',\n",
       " 'WLS',\n",
       " 'LRRC7',\n",
       " 'LRRC40',\n",
       " 'ANKRD13C',\n",
       " 'CTH',\n",
       " 'NEGR1',\n",
       " 'LRRIQ3',\n",
       " 'FPGT',\n",
       " 'FPGT-TNNI3K',\n",
       " 'CRYZ',\n",
       " 'TYW3',\n",
       " 'SLC44A5',\n",
       " 'ACADM',\n",
       " 'RABGGTB',\n",
       " 'MSH4',\n",
       " 'ST6GALNAC3',\n",
       " 'PIGK',\n",
       " 'AK5',\n",
       " 'ZZZ3',\n",
       " 'USP33',\n",
       " 'NEXN',\n",
       " 'FUBP1',\n",
       " 'DNAJB4',\n",
       " 'IFI44L',\n",
       " 'IFI44',\n",
       " 'TTLL7',\n",
       " 'PRKACB',\n",
       " 'SAMD13',\n",
       " 'RPF1',\n",
       " 'GNG5',\n",
       " 'CTBS',\n",
       " 'SSX2IP',\n",
       " 'MCOLN2',\n",
       " 'MCOLN3',\n",
       " 'SYDE2',\n",
       " 'C1orf52',\n",
       " 'BCL10',\n",
       " 'ZNHIT6',\n",
       " 'COL24A1',\n",
       " 'ODF2L',\n",
       " 'SH3GLB1',\n",
       " 'HS2ST1',\n",
       " 'LMO4',\n",
       " 'PKN2',\n",
       " 'GTF2B',\n",
       " 'RBMXL1',\n",
       " 'GBP3',\n",
       " 'GBP1',\n",
       " 'GBP2',\n",
       " 'GBP4',\n",
       " 'GBP5',\n",
       " 'LRRC8B',\n",
       " 'LRRC8C',\n",
       " 'LRRC8D',\n",
       " 'ZNF326',\n",
       " 'ZNF644',\n",
       " 'CDC7',\n",
       " 'TGFBR3',\n",
       " 'EPHX4',\n",
       " 'SETSIP',\n",
       " 'BTBD8',\n",
       " 'GLMN',\n",
       " 'RPAP2',\n",
       " 'GFI1',\n",
       " 'EVI5',\n",
       " 'MTF2',\n",
       " 'TMED5',\n",
       " 'CCDC18',\n",
       " 'BCAR3',\n",
       " 'GCLM',\n",
       " 'ARHGAP29',\n",
       " 'ABCD3',\n",
       " 'CNN3',\n",
       " 'ALG14',\n",
       " 'RWDD3',\n",
       " 'PTBP2',\n",
       " 'DPYD',\n",
       " 'FRRS1',\n",
       " 'AGL',\n",
       " 'SLC35A3',\n",
       " 'MFSD14A',\n",
       " 'SASS6',\n",
       " 'TRMT13',\n",
       " 'DBT',\n",
       " 'RTCA',\n",
       " 'CDC14A',\n",
       " 'EXTL2',\n",
       " 'SLC30A7',\n",
       " 'DPH5',\n",
       " 'S1PR1',\n",
       " 'RNPC3',\n",
       " 'PRMT6',\n",
       " 'NTNG1',\n",
       " 'VAV3',\n",
       " 'SLC25A24',\n",
       " 'FAM102B',\n",
       " 'HENMT1',\n",
       " 'STXBP3',\n",
       " 'GPSM2',\n",
       " 'CLCC1',\n",
       " 'WDR47',\n",
       " 'TAF13',\n",
       " 'TMEM167B',\n",
       " 'CELSR2',\n",
       " 'PSRC1',\n",
       " 'SORT1',\n",
       " 'PSMA5',\n",
       " 'CYB561D1',\n",
       " 'AMIGO1',\n",
       " 'GNAI3',\n",
       " 'AMPD2',\n",
       " 'GSTM4',\n",
       " 'GSTM3',\n",
       " 'CSF1',\n",
       " 'AHCYL1',\n",
       " 'STRIP1',\n",
       " 'RBM15',\n",
       " 'SLC16A4',\n",
       " 'KCNA3',\n",
       " 'LRIF1',\n",
       " 'DRAM2',\n",
       " 'CEPT1',\n",
       " 'DENND2D',\n",
       " 'CHI3L2',\n",
       " 'PIFO',\n",
       " 'OVGP1',\n",
       " 'WDR77',\n",
       " 'C1orf162',\n",
       " 'TMIGD3',\n",
       " 'ADORA3',\n",
       " 'DDX20',\n",
       " 'KCND3',\n",
       " 'CTTNBP2NL',\n",
       " 'WNT2B',\n",
       " 'ST7L',\n",
       " 'CAPZA1',\n",
       " 'MOV10',\n",
       " 'RHOC',\n",
       " 'PPM1J',\n",
       " 'SLC16A1',\n",
       " 'LRIG2',\n",
       " 'PHTF1',\n",
       " 'RSBN1',\n",
       " 'PTPN22',\n",
       " 'BCL2L15',\n",
       " 'AP4B1',\n",
       " 'DCLRE1B',\n",
       " 'HIPK1',\n",
       " 'TRIM33',\n",
       " 'DENND2C',\n",
       " 'NRAS',\n",
       " 'SIKE1',\n",
       " 'TSPAN2',\n",
       " 'VANGL1',\n",
       " 'SLC22A15',\n",
       " 'CD58',\n",
       " 'CD2',\n",
       " 'PTGFRN',\n",
       " 'CD101',\n",
       " 'TTF2',\n",
       " 'MAN1A2',\n",
       " 'GDAP2',\n",
       " 'WDR3',\n",
       " 'WARS2',\n",
       " 'ZNF697',\n",
       " 'PHGDH',\n",
       " 'REG4',\n",
       " 'NOTCH2',\n",
       " 'SEC22B',\n",
       " 'NBPF26',\n",
       " 'FCGR1B',\n",
       " 'FAM72B',\n",
       " 'SRGAP2C',\n",
       " 'FAM72C',\n",
       " 'NBPF15',\n",
       " 'SRGAP2B',\n",
       " 'FAM72D',\n",
       " 'NBPF20',\n",
       " 'GPR89A',\n",
       " 'PDZK1',\n",
       " 'CD160',\n",
       " 'RNF115',\n",
       " 'POLR3C',\n",
       " 'NUDT17',\n",
       " 'PIAS3',\n",
       " 'ITGA10',\n",
       " 'PEX11B',\n",
       " 'LIX1L',\n",
       " 'ANKRD34A',\n",
       " 'NBPF10',\n",
       " 'NBPF12',\n",
       " 'PRKAB2',\n",
       " 'FMO5',\n",
       " 'CHD1L',\n",
       " 'BCL9',\n",
       " 'ACP6',\n",
       " 'GPR89B',\n",
       " 'NBPF11',\n",
       " 'PPIAL4G',\n",
       " 'NBPF14',\n",
       " 'PDE4DIP',\n",
       " 'NBPF9',\n",
       " 'NBPF19',\n",
       " 'FCGR1A',\n",
       " 'BOLA1',\n",
       " 'SV2A',\n",
       " 'MTMR11',\n",
       " 'OTUD7B',\n",
       " 'VPS45',\n",
       " 'PLEKHO1',\n",
       " 'ANP32E',\n",
       " 'C1orf54',\n",
       " 'CIART',\n",
       " 'PRPF3',\n",
       " 'RPRD2',\n",
       " 'TARS2',\n",
       " 'ECM1',\n",
       " 'ADAMTSL4',\n",
       " 'MCL1',\n",
       " 'GOLPH3L',\n",
       " 'HORMAD1',\n",
       " 'CTSS',\n",
       " 'ARNT',\n",
       " 'SETDB1',\n",
       " 'CERS2',\n",
       " 'BNIPL',\n",
       " 'C1orf56',\n",
       " 'CDC42SE1',\n",
       " 'MLLT11',\n",
       " 'GABPB2',\n",
       " 'SEMA6C',\n",
       " 'TNFAIP8L2',\n",
       " 'SCNM1',\n",
       " 'LYSMD1',\n",
       " 'TMOD4',\n",
       " 'VPS72',\n",
       " 'PIP5K1A',\n",
       " 'ZNF687',\n",
       " 'RFX5',\n",
       " 'SELENBP1',\n",
       " 'POGZ',\n",
       " 'SNX27',\n",
       " 'MRPL9',\n",
       " 'OAZ3',\n",
       " 'RORC',\n",
       " 'THEM4',\n",
       " 'S100A10',\n",
       " 'S100A11',\n",
       " 'S100A9',\n",
       " 'S100A12',\n",
       " 'S100A8',\n",
       " 'S100A6',\n",
       " 'S100A5',\n",
       " 'S100A4',\n",
       " 'S100A3',\n",
       " 'S100A2',\n",
       " 'S100A13',\n",
       " 'CHTOP',\n",
       " 'ILF2',\n",
       " 'INTS3',\n",
       " 'SLC27A3',\n",
       " 'GATAD2B',\n",
       " 'DENND4B',\n",
       " 'CRTC2',\n",
       " 'SLC39A1',\n",
       " 'CREB3L4',\n",
       " 'RAB13',\n",
       " 'NUP210L',\n",
       " 'C1orf43',\n",
       " 'UBAP2L',\n",
       " 'AQP10',\n",
       " 'ATP8B2',\n",
       " 'IL6R',\n",
       " 'SHE',\n",
       " 'UBE2Q1',\n",
       " 'PMVK',\n",
       " 'PBXIP1',\n",
       " 'PYGO2',\n",
       " 'SHC1',\n",
       " 'CKS1B',\n",
       " 'FLAD1',\n",
       " 'ZBTB7B',\n",
       " 'ADAM15',\n",
       " 'EFNA4',\n",
       " 'EFNA3',\n",
       " 'EFNA1',\n",
       " 'SLC50A1',\n",
       " 'TRIM46',\n",
       " 'MUC1',\n",
       " 'MTX1',\n",
       " 'GBA',\n",
       " 'FAM189B',\n",
       " 'CLK2',\n",
       " 'HCN3',\n",
       " 'FDPS',\n",
       " 'RUSC1',\n",
       " 'MSTO1',\n",
       " 'YY1AP1',\n",
       " 'GON4L',\n",
       " 'SYT11',\n",
       " 'RIT1',\n",
       " 'UBQLN4',\n",
       " 'LAMTOR2',\n",
       " 'RAB25',\n",
       " 'MEX3A',\n",
       " 'LMNA',\n",
       " 'SEMA4A',\n",
       " 'SLC25A44',\n",
       " 'SMG5',\n",
       " 'TMEM79',\n",
       " 'GLMP',\n",
       " 'TSACC',\n",
       " 'MEF2D',\n",
       " 'TTC24',\n",
       " 'GPATCH4',\n",
       " 'ISG20L2',\n",
       " 'MRPL24',\n",
       " 'HDGF',\n",
       " 'PRCC',\n",
       " 'SH2D2A',\n",
       " 'ETV3',\n",
       " 'FCRL5',\n",
       " 'FCRL3',\n",
       " 'FCRL2',\n",
       " 'FCRL1',\n",
       " 'CD1D',\n",
       " 'CD1A',\n",
       " 'CD1C',\n",
       " 'CD1B',\n",
       " 'CD1E',\n",
       " 'MNDA',\n",
       " 'PYHIN1',\n",
       " 'IFI16',\n",
       " 'AIM2',\n",
       " 'FCER1A',\n",
       " 'DUSP23',\n",
       " 'FCRL6',\n",
       " 'SLAMF8',\n",
       " 'VSIG8',\n",
       " 'CFAP45',\n",
       " 'TAGLN2',\n",
       " 'SLAMF9',\n",
       " 'PIGM',\n",
       " 'IGSF8',\n",
       " 'ATP1A4',\n",
       " 'PEA15',\n",
       " 'DCAF8',\n",
       " 'PEX19',\n",
       " 'COPA',\n",
       " 'NCSTN',\n",
       " 'SLAMF6',\n",
       " 'CD84',\n",
       " 'SLAMF1',\n",
       " 'SLAMF7',\n",
       " 'LY9',\n",
       " 'CD244',\n",
       " 'ITLN1',\n",
       " 'F11R',\n",
       " 'USF1',\n",
       " 'KLHDC9',\n",
       " 'NIT1',\n",
       " 'DEDD',\n",
       " 'USP21',\n",
       " 'PPOX',\n",
       " 'ADAMTS4',\n",
       " 'NDUFS2',\n",
       " 'FCER1G',\n",
       " 'TOMM40L',\n",
       " 'NR1I3',\n",
       " 'FCGR2A',\n",
       " 'HSPA6',\n",
       " 'FCGR3A',\n",
       " 'FCGR3B',\n",
       " 'FCGR2B',\n",
       " 'FCRLA',\n",
       " 'FCRLB',\n",
       " 'DUSP12',\n",
       " 'ATF6',\n",
       " 'OLFML2B',\n",
       " 'SH2D1B',\n",
       " 'UHMK1',\n",
       " 'UAP1',\n",
       " 'DDR2',\n",
       " 'HSD17B7',\n",
       " 'RGS5',\n",
       " 'NUF2',\n",
       " 'PBX1',\n",
       " 'UCK2',\n",
       " 'POGK',\n",
       " 'TADA1',\n",
       " 'GPA33',\n",
       " 'POU2F1',\n",
       " 'CD247',\n",
       " 'CREG1',\n",
       " 'MPZL1',\n",
       " 'MPC2',\n",
       " 'DCAF6',\n",
       " 'GPR161',\n",
       " 'TIPRL',\n",
       " 'SFT2D2',\n",
       " 'XCL2',\n",
       " 'XCL1',\n",
       " 'ATP1B1',\n",
       " 'NME7',\n",
       " 'BLZF1',\n",
       " 'SLC19A2',\n",
       " 'F5',\n",
       " 'SELP',\n",
       " 'C1orf112',\n",
       " 'METTL18',\n",
       " 'SCYL3',\n",
       " 'KIFAP3',\n",
       " 'GORAB',\n",
       " 'FMO1',\n",
       " 'FMO4',\n",
       " 'VAMP4',\n",
       " 'METTL13',\n",
       " 'DNM3',\n",
       " 'SUCO',\n",
       " 'FASLG',\n",
       " 'TNFSF4',\n",
       " 'KLHL20',\n",
       " 'CENPL',\n",
       " 'DARS2',\n",
       " 'ZBTB37',\n",
       " 'RC3H1',\n",
       " 'RABGAP1L',\n",
       " 'CACYBP',\n",
       " 'MRPS14',\n",
       " 'KIAA0040',\n",
       " 'RALGPS2',\n",
       " 'FAM20B',\n",
       " 'TOR3A',\n",
       " 'ABL2',\n",
       " 'SOAT1',\n",
       " 'TOR1AIP2',\n",
       " 'TOR1AIP1',\n",
       " 'CEP350',\n",
       " 'QSOX1',\n",
       " 'ACBD6',\n",
       " 'XPR1',\n",
       " 'STX6',\n",
       " 'MR1',\n",
       " 'IER5',\n",
       " 'GLUL',\n",
       " 'RGSL1',\n",
       " 'RNASEL',\n",
       " 'RGS16',\n",
       " 'NPL',\n",
       " 'DHX9',\n",
       " 'SMG7',\n",
       " 'NCF2',\n",
       " 'ARPC5',\n",
       " 'RGL1',\n",
       " 'COLGALT2',\n",
       " 'TSEN15',\n",
       " 'C1orf21',\n",
       " 'EDEM3',\n",
       " 'RNF2',\n",
       " 'TRMT1L',\n",
       " 'SWT1',\n",
       " 'IVNS1ABP',\n",
       " 'TPR',\n",
       " 'PTGS2',\n",
       " 'PLA2G4A',\n",
       " 'RGS18',\n",
       " 'RGS1',\n",
       " 'RGS2',\n",
       " 'UCHL5',\n",
       " 'GLRX2',\n",
       " 'CDC73',\n",
       " 'B3GALT2',\n",
       " 'CFH',\n",
       " 'ASPM',\n",
       " 'ZBTB41',\n",
       " 'DENND1B',\n",
       " 'NEK7',\n",
       " 'ZNF281',\n",
       " 'KIF14',\n",
       " 'DDX59',\n",
       " 'KIF21B',\n",
       " 'ASCL5',\n",
       " 'TMEM9',\n",
       " 'PHLDA3',\n",
       " 'CSRP1',\n",
       " 'NAV1',\n",
       " 'IPO9',\n",
       " 'SHISA4',\n",
       " 'TIMM17A',\n",
       " 'RNPEP',\n",
       " 'ELF3',\n",
       " 'ARL8A',\n",
       " 'PTPN7',\n",
       " 'LGR6',\n",
       " 'UBE2T',\n",
       " 'PPP1R12B',\n",
       " 'KDM5B',\n",
       " 'RABIF',\n",
       " 'KLHL12',\n",
       " 'CYB5R1',\n",
       " 'TMEM183A',\n",
       " 'ADORA1',\n",
       " 'CHIT1',\n",
       " 'BTG2',\n",
       " 'PRELP',\n",
       " 'ATP2B4',\n",
       " 'LAX1',\n",
       " 'ZC3H11A',\n",
       " 'ZBED6',\n",
       " 'SOX13',\n",
       " 'ETNK2',\n",
       " 'PPP1R15B',\n",
       " 'PIK3C2B',\n",
       " 'LRRN2',\n",
       " 'TMEM81',\n",
       " 'RBBP5',\n",
       " 'DSTYK',\n",
       " 'TMCC2',\n",
       " 'NUAK2',\n",
       " 'CDK18',\n",
       " 'ELK4',\n",
       " 'SLC45A3',\n",
       " 'NUCKS1',\n",
       " 'RAB29',\n",
       " 'SLC41A1',\n",
       " 'RAB7B',\n",
       " 'FAM72A',\n",
       " 'SRGAP2',\n",
       " 'IKBKE',\n",
       " 'EIF2D',\n",
       " 'DYRK3',\n",
       " 'MAPKAPK2',\n",
       " 'IL10',\n",
       " 'IL19',\n",
       " 'FCMR',\n",
       " 'PIGR',\n",
       " 'PFKFB2',\n",
       " 'YOD1',\n",
       " 'C4BPB',\n",
       " 'CR2',\n",
       " 'CR1',\n",
       " 'CD34',\n",
       " 'PLXNA2',\n",
       " 'LAMB3',\n",
       " 'G0S2',\n",
       " 'HSD11B1',\n",
       " 'IRF6',\n",
       " 'HHAT',\n",
       " 'RCOR3',\n",
       " 'TRAF5',\n",
       " 'SLC30A1',\n",
       " 'NEK2',\n",
       " 'LPGAT1',\n",
       " 'INTS7',\n",
       " 'DTL',\n",
       " 'PPP2R5A',\n",
       " 'NENF',\n",
       " 'ATF3',\n",
       " 'BATF3',\n",
       " 'TATDN3',\n",
       " 'FLVCR1',\n",
       " 'VASH2',\n",
       " 'ANGEL2',\n",
       " 'RPS6KC1',\n",
       " 'SMYD2',\n",
       " 'PTPN14',\n",
       " 'CENPF',\n",
       " ...]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var['gene_symbols'].to_list().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32975)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_obj.dataset_to_protein_embeddings[dataset][10349]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0219,  0.0010,  0.0236,  ...,  0.0084, -0.0243, -0.0175]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.normalize(model.pe_embedding(dataset_obj.dataset_to_protein_embeddings[dataset][10349].to('cuda')).unsqueeze(0), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1075, 25, 5120])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0226, -0.0027,  0.0209,  ..., -0.0062, -0.0228, -0.0036],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences[2,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23557., device='cuda:0')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences_save[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6760"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var['gene_symbols'].to_list().index('STAT2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary from gene symbol to index \n",
    "gene_to_idx = dict(zip(adata.var['gene_symbols'], range(adata.var.shape[0])))\n",
    "\n",
    "pe_index = dataset_obj.dataset_to_protein_embeddings[dataset].numpy()\n",
    "\n",
    "gene_to_pe_index = { g: pe_index[i] for i, g in enumerate(adata.var['gene_symbols'].to_list())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write this to a pickle\n",
    "with open(\"./model_files/gene_to_pe_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gene_to_pe_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29700"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_to_pe_index['STAT2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2834]),)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(dataset_obj.dataset_to_protein_embeddings[dataset].numpy() == 23557)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28041, 26112, 20529, ..., 23672, 23677, 23680])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_obj.dataset_to_protein_embeddings[dataset].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1137,  0.0827,  0.1744,  ..., -0.0165,  0.0019, -0.1174],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pe_embedding(torch.tensor(29700).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
