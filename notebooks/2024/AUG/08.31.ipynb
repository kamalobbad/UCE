{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/oak/stanford/groups/akundaje/kobbad/UCE\")\n",
    "from model import *\n",
    "import scanpy as sc\n",
    "from tqdm.auto import tqdm\n",
    "from torch import nn, Tensor\n",
    "from evaluate import get_ESM2_embeddings\n",
    "from utils import get_ESM2_embeddings_x\n",
    "import argparse\n",
    "from accelerate import Accelerator\n",
    "from evaluate import AnndataProcessor\n",
    "from eval_data import MultiDatasetSentences, MultiDatasetSentenceCollator\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--num_knockin'], dest='num_knockin', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='Number of times to knockin gene', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description='Embed a single anndata using UCE.')\n",
    "\n",
    "# Anndata Processing Arguments\n",
    "parser.add_argument('--adata_path', type=str,\n",
    "                    default=None,\n",
    "                    help='Full path to the anndata you want to embed.')\n",
    "parser.add_argument('--dir', type=str,\n",
    "                    default=\"./\",\n",
    "                    help='Working folder where all files will be saved.')\n",
    "parser.add_argument('--species', type=str, default=\"human\",\n",
    "                    help='Species of the anndata.')\n",
    "parser.add_argument('--filter', type=bool, default=True,\n",
    "                    help='Additional gene/cell filtering on the anndata.')\n",
    "parser.add_argument('--skip', type=bool, default=True,\n",
    "                    help='Skip datasets that appear to have already been created.')\n",
    "\n",
    "# Model Arguments\n",
    "parser.add_argument('--model_loc', type=str,\n",
    "                    default=None,\n",
    "                    help='Location of the model.')\n",
    "parser.add_argument('--batch_size', type=int, default=25,\n",
    "                    help='Batch size.')\n",
    "parser.add_argument('--pad_length', type=int, default=1536,\n",
    "                    help='Batch size.')\n",
    "parser.add_argument(\"--pad_token_idx\", type=int, default=0,\n",
    "                    help=\"PAD token index\")\n",
    "parser.add_argument(\"--chrom_token_left_idx\", type=int, default=1,\n",
    "                    help=\"Chrom token left index\")\n",
    "parser.add_argument(\"--chrom_token_right_idx\", type=int, default=2,\n",
    "                    help=\"Chrom token right index\")\n",
    "parser.add_argument(\"--cls_token_idx\", type=int, default=3,\n",
    "                    help=\"CLS token index\")\n",
    "parser.add_argument(\"--CHROM_TOKEN_OFFSET\", type=int, default=143574,\n",
    "                    help=\"Offset index, tokens after this mark are chromosome identifiers\")\n",
    "parser.add_argument('--sample_size', type=int, default=1024,\n",
    "                    help='Number of genes sampled for cell sentence')\n",
    "parser.add_argument('--CXG', type=bool, default=True,\n",
    "                    help='Use CXG model.')\n",
    "parser.add_argument('--nlayers', type=int, default=4,\n",
    "                    help='Number of transformer layers.')\n",
    "parser.add_argument('--output_dim', type=int, default=1280,\n",
    "                    help='Output dimension.')\n",
    "parser.add_argument('--d_hid', type=int, default=5120,\n",
    "                    help='Hidden dimension.')\n",
    "parser.add_argument('--token_dim', type=int, default=5120,\n",
    "                    help='Token dimension.')\n",
    "parser.add_argument('--multi_gpu', type=bool, default=False,\n",
    "                    help='Use multiple GPUs')\n",
    "\n",
    "# Misc Arguments\n",
    "parser.add_argument(\"--spec_chrom_csv_path\",\n",
    "                    default=\"./model_files/species_chrom.csv\", type=str,\n",
    "                    help=\"CSV Path for species genes to chromosomes and start locations.\")\n",
    "parser.add_argument(\"--token_file\",\n",
    "                    default=\"./model_files/all_tokens.torch\", type=str,\n",
    "                    help=\"Path for token embeddings.\")\n",
    "parser.add_argument(\"--protein_embeddings_dir\",\n",
    "                    default=\"./model_files/protein_embeddings/\", type=str,\n",
    "                    help=\"Directory where protein embedding .pt files are stored.\")\n",
    "parser.add_argument(\"--offset_pkl_path\",\n",
    "                    default=\"./model_files/species_offsets.pkl\", type=str,\n",
    "                        help=\"PKL file which contains offsets for each species.\")\n",
    "\n",
    "# masking arguments\n",
    "parser.add_argument(\"--genes_to_mask\", \n",
    "                    nargs='+',\n",
    "                    default= None,\n",
    "                    type=str,\n",
    "                    help=\"List of genes to mask\")\n",
    "\n",
    "parser.add_argument(\"--genes_to_pe_idx\",\n",
    "                    default=\"./model_files/gene_to_pe_index.pkl\",type=str,\n",
    "                    help=\"Path to gene to protein embedding index mapping\")\n",
    "parser.add_argument(\"--num_knockin\", \n",
    "                        default=1,\n",
    "                        type=int,\n",
    "                        help=\"Number of times to knockin gene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STAT2']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser.parse_args()\n",
    "\n",
    "args.gene_to_knockin = [\"STAT2\"]\n",
    "\n",
    "args.gene_to_knockin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_loc = \"/oak/stanford/groups/akundaje/kobbad/UCE/model_files/4layer_model.torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "#### Set up the model ####\n",
    "token_dim = args.token_dim\n",
    "emsize = 1280  # embedding dimension\n",
    "d_hid = args.d_hid  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = args.nlayers  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 20  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.05  # dropout probability\n",
    "model = TransformerModel(token_dim=token_dim, d_model=emsize, nhead=nhead,\n",
    "                            d_hid=d_hid,\n",
    "                            nlayers=nlayers, dropout=dropout,\n",
    "                            output_dim=args.output_dim)\n",
    "\n",
    "# intialize as empty\n",
    "empty_pe = torch.zeros(145469, 5120)\n",
    "empty_pe.requires_grad = False\n",
    "model.pe_embedding = nn.Embedding.from_pretrained(empty_pe)\n",
    "model.load_state_dict(torch.load(args.model_loc, map_location=\"cpu\"),\n",
    "                        strict=True)\n",
    "# Load in the real token embeddings\n",
    "all_pe = get_ESM2_embeddings(args)\n",
    "\n",
    "if all_pe.shape[0] != 145469: \n",
    "        all_pe.requires_grad = False\n",
    "        model.pe_embedding = nn.Embedding.from_pretrained(all_pe)\n",
    "\n",
    "model = model.eval()\n",
    "accelerator = Accelerator(project_dir=args.dir)\n",
    "model = accelerator.prepare(model)\n",
    "batch_size = args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sample AnnData: 10k pbmcs dataset\n",
      "10k_pbmcs_proc already processed. Skipping\n",
      "PE Idx, Chrom and Starts files already created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 11990 × 10809\n",
       "    obs: 'n_counts', 'batch', 'labels', 'str_labels', 'cell_type', 'n_genes'\n",
       "    var: 'gene_symbols', 'n_counts-0', 'n_counts-1', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'n_cells'\n",
       "    uns: 'cell_types', 'hvg'\n",
       "    obsm: 'design', 'normalized_qc', 'qc_pc', 'raw_qc'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = AnndataProcessor(args, accelerator)\n",
    "processor.preprocess_anndata()\n",
    "processor.generate_idxs()\n",
    "processor.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(processor.shapes_dict_path, \"rb\") as f:\n",
    "            shapes_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiDatasetSentences(sorted_dataset_names=[processor.name],\n",
    "                                shapes_dict=shapes_dict,\n",
    "                                args=args, npzs_dir=args.dir,\n",
    "                                dataset_to_protein_embeddings_path=processor.pe_idx_path,\n",
    "                                datasets_to_chroms_path=processor.chroms_path,\n",
    "                                datasets_to_starts_path=processor.starts_path\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10809])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset_to_protein_embeddings[dataset.datasets[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10k_pbmcs_proc']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10809])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seems to have the mapping from gene to protein embeddings\n",
    "dataset.dataset_to_protein_embeddings['10k_pbmcs_proc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28041, 26112, 20529,  ..., 23672, 23677, 23680])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset_to_protein_embeddings[dataset.datasets[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_dataset_sentence_collator = MultiDatasetSentenceCollator(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29700]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_dataset_sentence_collator.idx_to_knockin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                            collate_fn=multi_dataset_sentence_collator,\n",
    "                            num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(accelerator.device)\n",
    "x = accelerator.prepare(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = x[0].to(accelerator.device)\n",
    "msk = x[1].to(accelerator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sentences, mask = bs, msk\n",
    "batch_sentences = batch_sentences.permute(1,0)\n",
    "\n",
    "batch_sentences = model.pe_embedding(batch_sentences.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sentences = nn.functional.normalize(batch_sentences,\n",
    "                                                      dim=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, embedding = model.forward(batch_sentences, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 1280])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
